context:
  version: 3.1.0
  # Triton no longer tags releases, but there are release branches, e.g.
  # https://github.com/triton-lang/triton/commits/release/3.1.x/
  # Check if the commit id from Pytorch's latest pinned commit in
  # https://github.com/pytorch/pytorch/blob/v{{ pytorch_ver }}/.ci/docker/ci_commit_pins/triton.txt
  # can be found on one of those release branches, and use that as the version
  git_commit: 5fe38ffd73c2ac6ed6323b554205186696631c6f
  build_number: 3

package:
  name: triton
  version: ${{ version }}

source:
  url: https://github.com/openai/triton/archive/${{ git_commit }}.tar.gz
  sha256: 933babc32b69872efbce05fe8be61129fecf52c724fadea42d8c7b2d10e16ad9
  patches:
    - patches/0001-Remove-Werror-that-cause-false-positive-build-failur.patch
    # https://github.com/triton-lang/triton/commit/e4569136f3821ad3d99bef43254bf935c1c96f42
    - patches/0002-BACKEND-Update-LLVM-version-to-https-github.com-llvm.patch
    # https://github.com/triton-lang/triton/commit/cd4a172c79c69fff91b893c2e5deb78a7a887c26
    - patches/0003-BACKEND-Update-LLVM-version-to-https-github.com-llvm.patch
    # https://github.com/triton-lang/triton/commit/3e233d7ccd62bc7a29eb5266c80b379cef1f6132
    - patches/0004-BACKEND-Update-LLVM-to-llvm-llvm-project-657ec7320d8.patch
    # https://github.com/triton-lang/triton/commit/e8873ae7dfe68eda04d7656ec93627afe8dc56a1
    - patches/0005-BACKEND-Update-LLVM-version-to-https-github.com-llvm.patch
    # https://github.com/triton-lang/triton/commit/46550ab18e8f7314107cf591b9cf902b290fd45d
    - patches/0006-BACKEND-Update-LLVM-version-to-https-github.com-llvm.patch
    # diff between main branch:
    # https://github.com/triton-lang/triton/commit/cf2ad02324fc253970c3ab2666e775406405f213
    # and 3.1.x branch:
    # https://github.com/triton-lang/triton/commit/757b6a61e7df814ba806f498f8bb3160f84b120c
    - patches/0007-Update-config.enableRegionSimplification-for-LLVM-19.patch
    - patches/0008-Do-not-link-directly-to-LLVM-static-libraries.patch
    # https://github.com/triton-lang/triton/commit/f48dbc1b106c93144c198fbf3c4f30b2aab9d242
    - patches/0009-CODEGEN-Support-CUDA-12.6-4588.patch
    - patches/0010-Use-system-PATH-to-find-tools-in-CONDA_PREFIX.patch
    # https://github.com/triton-lang/triton/commit/0591b3756bd4143b7163235c0eca4d718948e982
    - patches/0011-Don-t-specify-A-x64-option-and-reuse-cmake-build-typ.patch
    # https://github.com/triton-lang/triton/commit/3bfdbc0cba3e4838364bf6bd204fa522e1665458
    # (use removed earlier)
    - patches/0012-remove-unused-requirement-filelock-4356.patch

build:
  number: ${{ build_number }}
  string: cuda${{ cuda_compiler_version | version_to_buildstring }}py${{ python | version_to_buildstring }}h${{ hash }}_${{ build_number }}
  # TODO: CPU-only support still under development
  # No success enabling Windows build as of 3.1.0:
  # https://github.com/conda-forge/triton-feedstock/pull/29#issuecomment-2564371725
  skip: "win or cuda_compiler_version == \"None\""

requirements:
  build:
    - ${{ compiler('cxx') }}
    - ${{ compiler('cuda') }}
    - ${{ stdlib('c') }}
    - ninja
    - cmake
    - mlir
    - if: win
      then: m2-sed
      else: sed
    - if: build_platform != target_platform
      then:
        - python
        - cross-python_${{ target_platform }}
  host:
    - python
    - pybind11
    - pip
    - setuptools
    - llvmdev
    - mlir
    - zlib
    - nlohmann_json
    - cuda-cupti-dev
  run:
    - python
    - setuptools
    - cuda-nvcc
    - cuda-cuobjdump
    - cuda-cudart
    - cuda-cupti

tests:
  - if: build_platform == target_platform
    then:
      - python:
          imports:
            - triton
            - triton._C.libtriton
          pip_check: true
      - files:
          source:
            - python/test/
        requirements:
          run:
            - pip
            - pytest
            - scipy
        script:
          # test suite essentially depends on availability of a physical GPU,
          # see https://github.com/openai/triton/issues/466;
          # run a test that does not require a GPU but checks
          # if triton.compile() works
          - pytest -v python/test/unit/tools/test_aot.py::test_ttgir_to_ptx

about:
  license: MIT
  license_file: LICENSE
  summary: Development repository for the Triton language and compiler
  description: |
    This is the development repository of Triton, a language and compiler for writing highly efficient custom Deep-Learning primitives.
    The aim of Triton is to provide an open-source environment to write fast code at higher productivity than CUDA, but also with higher flexibility than other existing DSLs.
  homepage: https://github.com/openai/triton
  repository: https://github.com/openai/triton
  documentation: https://triton-lang.org/

extra:
  recipe-maintainers:
    - erip
    - h-vetinari
